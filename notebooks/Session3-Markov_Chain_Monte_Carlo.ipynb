{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 3: Markov Chain Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import warnings\n",
    "\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import polars as pl\n",
    "import pymc as pm\n",
    "import scipy.stats as st\n",
    "from plotly.subplots import make_subplots\n",
    "from itertools import takewhile\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "if platform.system() == 'Linux':\n",
    "    # Multiprocessing behaves oddly on Linux, so we need to set the start method\n",
    "    import multiprocessing as mp\n",
    "    mp.set_start_method('spawn', force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Computation\n",
    "\n",
    "Lets take a look at [Bayes formula](https://en.wikipedia.org/wiki/Bayes%27_theorem):\n",
    "\n",
    "$$P(\\theta|x) = \\frac{P(x|\\theta) P(\\theta)}{P(x)}$$\n",
    "\n",
    "We have $P(\\theta|x)$, the probability of our model parameters $\\theta$ given the data $x$ and thus our quantity of interest. To compute this we multiply the prior $P(\\theta)$ (what we think about $\\theta$ before we have seen any data) and the likelihood $P(x|\\theta)$, i.e. how we think our data is distributed. This nominator is pretty easy to solve for.\n",
    "\n",
    "However, lets take a closer look at the denominator. $P(x)$ which is also called the evidence (i.e. the evidence that the data x was generated by this model). We can compute this quantity by integrating over all possible parameter values:\n",
    "$$P(x) = \\int_\\Theta P(x, \\theta) \\, \\mathrm{d}\\theta$$\n",
    "\n",
    "This is the key difficulty with Bayes formula -- while the formula looks innocent enough, for even slightly non-trivial models you just can't compute the posterior in closed-form. \n",
    "\n",
    "## Numerical Integration\n",
    "\n",
    "Bayesian analysis often requires **integration over multiple dimensions** that is intractable both via analytic methods or standard methods of numerical integration.\n",
    "However, it is often possible to compute these integrals by **simulating**\n",
    "(drawing samples) from posterior distributions. For example, consider the expected value of a random variable $\\mathbf{x}$:\n",
    "\n",
    "$$E[\\mathbf{x}] = \\int \\mathbf{x} f(\\mathbf{x}) d\\mathbf{x}, \\qquad\\mathbf{x} = x_1, \\ldots ,x_k$$\n",
    "\n",
    "where $k$ (the dimension of vector $x$) is perhaps very large. If we can produce a reasonable number of random vectors $\\{{\\bf x_i}\\}$, we can use these values to approximate the unknown integral. This process is known as *Monte Carlo integration*. In general, MC integration allows integrals against probability density functions:\n",
    "\n",
    "$$I = \\int h(\\mathbf{x}) f(\\mathbf{x}) \\mathbf{dx}$$\n",
    "\n",
    "to be estimated by finite sums:\n",
    "\n",
    "$$\\hat{I} = \\frac{1}{n}\\sum_{i=1}^n h(\\mathbf{x}_i),$$\n",
    "\n",
    "where $\\mathbf{x}_i$ is a sample from $f$. This estimate is valid and useful because:\n",
    "\n",
    "-   By the strong law of large numbers:\n",
    "\n",
    "$$\\hat{I} \\rightarrow I   \\text{   with probability 1}$$\n",
    "\n",
    "-   Simulation error can be measured and controlled:\n",
    "\n",
    "$$Var(\\hat{I}) = \\frac{1}{n(n-1)}\\sum_{i=1}^n (h(\\mathbf{x}_i)-\\hat{I})^2$$\n",
    "\n",
    "### How is this relevant to Bayesian analysis? \n",
    "\n",
    "In the context of Bayesian analysis, if we replace $f(\\mathbf{x})$\n",
    "with a posterior, $p(\\theta|y)$ and make $h(\\theta)$ an interesting function of the unknown parameter, the resulting expectation is that of the posterior of $h(\\theta)$:\n",
    "\n",
    "$$E[h(\\theta)|y] = \\int h(\\theta) p(\\theta|y) d\\theta \\approx \\frac{1}{n}\\sum_{i=1}^n h(\\theta)$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejection Sampling\n",
    "\n",
    "Most integrals are hard or impossible to do. Also, if we are iterating on a statistical model, we may want a method that works without requiring rederiving a formula for generating samples. Further, in Bayesian data analysis, we may not know a *normalizing constant*: we may only know \n",
    "\n",
    "$$\n",
    "\\tilde{p}(x) = \\frac{1}{Z_p}p(x),\n",
    "$$\n",
    "\n",
    "for some constant $Z_p$ (\"constant\" here is with respect to $x$). In order to sample, first we\n",
    "\n",
    "1. Choose a **proposal distribution** $q$ that you know how to sample from\n",
    "2. Choose a number $k$, so that $kq(x) \\geq \\tilde{p}(x)$ for all $x$\n",
    "\n",
    "Then, we repeatedly \n",
    "\n",
    "1. Draw a $z$ from $q$\n",
    "2. Draw a $u$ from $\\operatorname{Uniform}(0, kq(z))$\n",
    "3. If $u \\leq p(x)$, accept the draw, otherwise, reject.\n",
    "\n",
    "Importantly, every \"rejection\" is wasted computation! We will explore methods for having less wasted computation later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Mixture of Gaussians\n",
    "\n",
    "We can sample from the pdf returned by `mixture_of_gaussians` using rejection sampling. We will implement this as a Python generator, and yield the proposed draw, `z`, as well as whether it was accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixture_of_gaussians():\n",
    "    rvs = (st.norm(-3, 1), st.norm(0, 1), st.norm(3, 1))\n",
    "    probs = (0.5, 0.2, 0.3)\n",
    "    def pdf(x):\n",
    "        return sum(p * rv.pdf(x) for p, rv in zip(probs, rvs))\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(19)\n",
    "pdf = mixture_of_gaussians()\n",
    "t = np.linspace(-10, 10, 500)\n",
    "q = st.norm(0, 3)\n",
    "z = q.rvs()\n",
    "u = np.random.rand() * q.pdf(z)\n",
    "k = 3\n",
    "\n",
    "go.Figure().add_trace(\n",
    "    go.Scatter(\n",
    "        x=t, \n",
    "        y=[pdf(x) for x in t], \n",
    "        mode='lines', \n",
    "        name='p(x)',\n",
    "        line=dict(color='blue')\n",
    "    )\n",
    ").add_trace(\n",
    "    go.Scatter(\n",
    "        x=t,\n",
    "        y=[pdf(x) for x in t],\n",
    "        mode='none',\n",
    "        fill='tozeroy',\n",
    "        fillcolor='rgba(0, 0, 255, 0.2)',\n",
    "        showlegend=False\n",
    "    )\n",
    ").add_trace(\n",
    "    go.Scatter(\n",
    "        x=t, \n",
    "        y=k * q.pdf(t), \n",
    "        mode='lines', \n",
    "        name='k · N(z | 0, 3)',\n",
    "        line=dict(color='orange')\n",
    "    )\n",
    ").add_trace(\n",
    "    go.Scatter(\n",
    "        x=t,\n",
    "        y=k * q.pdf(t),\n",
    "        mode='none',\n",
    "        fill='tonexty',\n",
    "        fillcolor='rgba(255, 165, 0, 0.2)',\n",
    "        showlegend=False\n",
    "    )\n",
    ").add_shape(\n",
    "    type=\"line\",\n",
    "    x0=z, x1=z,\n",
    "    y0=0, y1=pdf(z),\n",
    "    line=dict(color=\"green\", dash=\"dash\")\n",
    ").add_shape(\n",
    "    type=\"line\",\n",
    "    x0=z, x1=z,\n",
    "    y0=pdf(z), y1=k * q.pdf(z),\n",
    "    line=dict(color=\"red\", dash=\"dash\"),\n",
    ").add_trace(\n",
    "    go.Scatter(\n",
    "        x=[z], \n",
    "        y=[pdf(z)], \n",
    "        mode='markers', \n",
    "        marker=dict(size=15, color='blue', line=dict(width=2, color='white')),\n",
    "        name='p(z)',\n",
    "        showlegend=False\n",
    "    )\n",
    ").add_trace(\n",
    "    go.Scatter(\n",
    "        x=[z], \n",
    "        y=[u], \n",
    "        mode='markers', \n",
    "        marker=dict(size=9, symbol='star', color='green'),\n",
    "        name='u ~ U(0, k·N(z | 0, 3))'\n",
    "    )\n",
    ").add_trace(\n",
    "    go.Scatter(\n",
    "        x=[z], \n",
    "        y=[k * q.pdf(z)], \n",
    "        mode='markers', \n",
    "        marker=dict(size=15, color='orange', line=dict(width=2, color='white')),\n",
    "        name='k·q(z)',\n",
    "        showlegend=False\n",
    "    )\n",
    ").update_layout(\n",
    "    width=750, \n",
    "    height=375,\n",
    "    xaxis=dict(range=[-10, 10]),\n",
    "    yaxis=dict(range=[0, 0.45]),\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### What is a Generator?\n",
    "> A Python generator is a special type of iterator that allows you to iterate over a sequence of values lazily, meaning it generates values on-the-fly and only when requested, rather than storing the entire sequence in memory. This is accomplished using the `yield` statement within a function, which produces a value and pauses the function's execution, resuming from that point when the next value is requested. Thus, instead of generating and storing all values at once, which can be resource-intensive, generators produce values one at a time, thus reducing memory overhead and allowing for the handling of infinite sequences or very large data sets that would be impractical to store in memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have a function that uses a generator to `yield` samples from a given target distribution and proposal, and a second function that orchestrates the sampling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejection_sampler(pdf, proposal_dist, k):\n",
    "    while True:\n",
    "        # Generate proposal\n",
    "        z = proposal_dist.rvs()\n",
    "        q_dist = proposal_dist.pdf(z)\n",
    "        # Draw uniformly from 0 to k * q(z)\n",
    "        u = k * np.random.rand() * q_dist\n",
    "        # Check our envelope condition\n",
    "        assert k * q_dist >= pdf(z)\n",
    "        if u <= pdf(z):\n",
    "            accept = True\n",
    "        else:\n",
    "            accept = False\n",
    "        yield z, accept\n",
    "\n",
    "def gen_samples(draws, sampler):\n",
    "    samples = []\n",
    "    for n_draws, (z, accept) in enumerate(sampler, start=1):\n",
    "        if accept:\n",
    "            samples.append(z)\n",
    "            if len(samples) == draws:\n",
    "                return np.array(samples), n_draws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that if $kq(x)$ is not larger than $\\tilde{p}(x)$, an exception is thrown.\n",
    "\n",
    "Let's try to recover the mixture distribution with rejection sampling. We will use a normal distribution as our proposal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = mixture_of_gaussians()\n",
    "proposal_dist = st.norm(0, 3)\n",
    "k = 4\n",
    "N = 10_000\n",
    "\n",
    "samples, draws = gen_samples(N, rejection_sampler(pdf, proposal_dist, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(samples.min(), samples.max(), 500)\n",
    "pdf_values = [pdf(x) for x in t]\n",
    "\n",
    "hist = go.Histogram(\n",
    "    x=samples,\n",
    "    histnorm='probability density',\n",
    "    name='Samples',\n",
    "    marker=dict(color='rgba(0, 0, 255, 0.7)'),\n",
    "    autobinx=True\n",
    ")\n",
    "\n",
    "pdf_curve = go.Scatter(\n",
    "    x=t,\n",
    "    y=pdf_values,\n",
    "    mode='lines',\n",
    "    name='True PDF',\n",
    "    line=dict(color='orange', width=2)\n",
    ")\n",
    "\n",
    "go.Figure(\n",
    "    data=[hist, pdf_curve]\n",
    ").update_layout(\n",
    "    title=f'{samples.size:,d} draws from the pdf with {100 * samples.size / draws:.2f}% efficiency',\n",
    "    xaxis_title='Value',\n",
    "    yaxis_title='Density',\n",
    "    width=750,\n",
    "    height=525,\n",
    "    bargap=0.01,\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does a rejection sampler scale with dimension?\n",
    "\n",
    "Let's use a multivariate Gaussian with identity covariance matrix as a target distribution, and a multivariate Gaussian with covariance matrix `1.1 * I` as the proposal. Should be easy, right? \n",
    "\n",
    "- Around what percent of samples are accepted with dimension 1? \n",
    "- 10 dimensions? \n",
    "- 100 dimensions? \n",
    "- What happens if you try to use 1,000 dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 1\n",
    "\n",
    "def finite_sampler(attempts, sampler):\n",
    "    samples = []\n",
    "    for n_draws, (z, accept) in takewhile(lambda j: j[0] < attempts, enumerate(sampler)):\n",
    "        if accept:\n",
    "            samples.append(z)\n",
    "    return np.array(samples)        \n",
    "\n",
    "pdf = st.multivariate_normal(np.zeros(DIM), np.eye(DIM)).pdf\n",
    "proposal_dist = st.multivariate_normal(np.zeros(DIM), 1.1 * np.eye(DIM))\n",
    "k = pdf(0) / proposal_dist.pdf(0)\n",
    "\n",
    "sampler = rejection_sampler(pdf, proposal_dist, k)\n",
    "\n",
    "samples = finite_sampler(1_000, sampler)\n",
    "\n",
    "print(f\"Acceptance rate: {len(samples) / 1000:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to MCMC\n",
    "\n",
    "One way to intuitively waste less computation is to use knowledge from your current sample to inform your next proposal: this is called a **Markov chain**. \n",
    "\n",
    "\n",
    "> ## Markov Chains\n",
    ">\n",
    "> A Markov chain is a special type of *stochastic process*. The standard definition of a stochastic process is an ordered collection of random variables:\n",
    ">\n",
    "> $$\\{X_t: t \\in T\\}$$\n",
    "> \n",
    "> where $t$ is frequently (but not necessarily) a time index. If we think of $X_t$ as a state $X$ at time $t$, and invoke the following dependence condition on each state:\n",
    "> \n",
    "> $$Pr(X_{t+1}=x_{t+1} | X_t=x_t, X_{t-1}=x_{t-1},\\ldots,X_0=x_0) = Pr(X_{t+1}=x_{t+1} | X_t=x_t)$$\n",
    "> \n",
    "> then the stochastic process is known as a Markov chain. This conditioning specifies that the future depends on the current state, but not past states.\n",
    "\n",
    "\n",
    "\n",
    "Let $t$ be the index of our current sample, $x_t$ be our current sample, and $\\operatorname{pdf}(x_t)$ be our probability density function evaluated at the current sample. We will define a *transition probability* that is conditioned on our current position: $T(x_{t + 1} | x_t)$. \n",
    "\n",
    "Critically, a Markov chain will sample from $\\operatorname{pdf}$ if:\n",
    "\n",
    "- $T$ is ergodic (this means $T$ is aperiodic and can explore the whole space)\n",
    "- The chain satisfies the *detailed balance* condition, which says that $\\operatorname{pdf}(x_t)T(x_{t+1} | x_t) = \\operatorname{pdf}(x_{t + 1})T(x_{t} | x_{t + 1})$.\n",
    "\n",
    "This second criteria inspires the *Metropolis acceptance criterion*: If we use any proposal with density function $\\operatorname{prop}$, we use this criterion to \"correct\" the transition probability to satisfy detailed balance:\n",
    "\n",
    "$$\n",
    "A(x_{t + 1} | x_t) = \\min\\left\\{1, \\frac{\\operatorname{pdf}(x_{t + 1})}{\\operatorname{pdf}(x_{t})}\\frac{\\operatorname{prop}(x_{t} | x_{t + 1})}{\\operatorname{prop}(x_{t + 1} | x_t)} \\right\\}\n",
    "$$\n",
    "\n",
    "Now the *Metropolis-Hastings Algorithm* is\n",
    "\n",
    "Initialize at some point $x_0$. For each iteration:\n",
    "\n",
    "1. Draw $\\tilde{x}_{t + 1} \\sim \\operatorname{prop}(x_t)$\n",
    "2. Draw $u \\sim \\operatorname{Uniform}(0, 1)$\n",
    "3. If $u < A(\\tilde{x}_{t + 1} | x_t)$, then $x_{t + 1} = \\tilde{x}_{t + 1}$. Otherwise, $x_{t + 1} = x_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the rejection sampler, below is a function to generate Metropolis-Hastings samples and a second function to orchestrate the sampling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings(pdf, prop_dist, init=0):\n",
    "    \"\"\"Yields a sample, and whether it was accepted.\"\"\"\n",
    "    current = init\n",
    "    while True:\n",
    "        prop = prop_dist.rvs()\n",
    "        p_accept = min(1, pdf(prop) / pdf(current) * prop_dist.pdf(current) / prop_dist.pdf(prop))\n",
    "        accept = np.random.rand() < p_accept\n",
    "        if accept:\n",
    "            current = prop\n",
    "        yield current, accept\n",
    "        \n",
    "def gen_samples(draws, sampler):\n",
    "    \"\"\"An example of using the metropolis_hastings API.\"\"\"\n",
    "    samples = np.empty(draws)\n",
    "    accepts = 0\n",
    "    for idx, (z, accept) in takewhile(lambda j: j[0] < draws, enumerate(sampler)):\n",
    "        accepts += int(accept)\n",
    "        samples[idx] = z\n",
    "    return samples, accepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this on the mixture of Gaussians example. Again, we will use a normal distribution as our proposal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = mixture_of_gaussians()\n",
    "proposal_dist = st.norm(0, 10)\n",
    "\n",
    "samples, accepts = gen_samples(10_000, metropolis_hastings(pdf, proposal_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(samples.min(), samples.max(), 500)\n",
    "pdf_values = [pdf(x) for x in t]\n",
    "\n",
    "hist = go.Histogram(\n",
    "    x=samples,\n",
    "    histnorm='probability density',\n",
    "    name='Samples',\n",
    "    marker=dict(color='rgba(0, 0, 255, 0.7)'),\n",
    "    nbinsx=30\n",
    ")\n",
    "\n",
    "pdf_curve = go.Scatter(\n",
    "    x=t,\n",
    "    y=pdf_values,\n",
    "    mode='lines',\n",
    "    name='True PDF',\n",
    "    line=dict(color='orange', width=2)\n",
    ")\n",
    "\n",
    "go.Figure(\n",
    "    data=[hist, pdf_curve]\n",
    ").update_layout(\n",
    "    title=f'{samples.size:,d} draws from the pdf with {100 * accepts / samples.size:.2f}% accept rate',\n",
    "    xaxis_title='Value',\n",
    "    yaxis_title='Density',\n",
    "    width=750,\n",
    "    height=525,\n",
    "    bargap=0.01,\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good, but implementation above is rather inefficient! \n",
    "\n",
    "We will speed it up by fixing the proposal distribution as a Gaussian **centered** at the previous point. Specifically,\n",
    "$$x_{t+1} \\sim \\mathcal{N}( x_t, \\sigma),$$\n",
    "so\n",
    "$$\\operatorname{prop}(x_{t+1} | x_{t}) = \\mathcal{N}(x_{t + 1} | x_t, \\sigma)$$\n",
    "\n",
    "This is a *random walk* proposal, where $\\sigma$ is the **step size**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk Metropolis-Hastings\n",
    "\n",
    "A common special case of Metropolis-Hastings is random walk Metropolis-Hastings. In random walk MCMC, the proposal distribution is symmetric around the current position. This simplifies the acceptance ratio calculation because the ratio of the proposal distributions cancels out:\n",
    "\n",
    "$$A(x_{t + 1} | x_t) = \\min\\left\\{1, \\frac{\\operatorname{pdf}(x_{t + 1})}{\\operatorname{pdf}(x_{t})}\\right\\}$$\n",
    "\n",
    "This is actually both simpler to implement and more efficient for generating samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_metropolis(pdf, step_size, init=0):\n",
    "    \"\"\"Random walk Metropolis algorithm\"\"\"\n",
    "    current = init\n",
    "    while True:\n",
    "        # Random walk proposal\n",
    "        prop = current + np.random.normal(0, step_size)\n",
    "        # Simple acceptance ratio (proposal terms cancel out)\n",
    "        p_accept = min(1, pdf(prop) / pdf(current))\n",
    "        accept = np.random.rand() < p_accept\n",
    "        if accept:\n",
    "            current = prop\n",
    "        yield current, accept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The critical hyperparameter in random walk Metropolis-Hastings is the step size, $\\sigma$. If $\\sigma$ is too small, the chain will take small steps and converge slowly. If $\\sigma$ is too large, the chain will reject many proposals and converge slowly.\n",
    "\n",
    "\n",
    "The optimal step size balances the **exploration** of a large step size and the **exploitation** of a small step size. A common rule of thumb is to set the acceptance rate to be around 1/4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = mixture_of_gaussians()\n",
    "\n",
    "# Create subplots\n",
    "fig = make_subplots(rows=3, cols=1, \n",
    "                   subplot_titles=[\"Step size: 0.1\", \"Step size: 1.0\", \"Step size: 5.0\"],\n",
    "                   vertical_spacing=0.1,\n",
    "                   specs=[[{\"type\": \"xy\"}], [{\"type\": \"xy\"}], [{\"type\": \"xy\"}]])\n",
    "\n",
    "# Try different step sizes\n",
    "step_sizes = [0.1, 8.0, 70.0]\n",
    "\n",
    "for i, step_size in enumerate(step_sizes, 1):\n",
    "    # Generate samples\n",
    "    samples, accepts = gen_samples(10_000, random_walk_metropolis(pdf, step_size))\n",
    "    \n",
    "    # Calculate t and pdf values for the line\n",
    "    t = np.linspace(samples.min(), samples.max(), 500)\n",
    "    pdf_values = [pdf(x) for x in t]\n",
    "    \n",
    "    # Add histogram\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=samples,\n",
    "            histnorm='probability density',\n",
    "            marker=dict(color='rgba(0, 0, 255, 0.7)'),\n",
    "            name=f\"Samples (step={step_size})\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=i, col=1\n",
    "    )\n",
    "    \n",
    "    # Add PDF line\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=t,\n",
    "            y=pdf_values,\n",
    "            mode='lines',\n",
    "            line=dict(color='orange', width=2),\n",
    "            name=f\"True PDF (step={step_size})\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=i, col=1\n",
    "    )\n",
    "    \n",
    "    # Update subplot title to include accept rate\n",
    "    fig.layout.annotations[i-1].text = f\"Step size: {step_size}, Accept rate: {100 * accepts / samples.size:.2f}%\"\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=750,\n",
    "    width=750,\n",
    "    bargap=0.01,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_xaxes(title_text=\"Value\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"Density\", row=2, col=1)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamiltonian Monte Carlo\n",
    "\n",
    "While flexible and easy to implement, Metropolis-Hastings sampling is a random walk\n",
    "sampler that might not be statistically efficient for many models. Specifically, for models of **high dimension**, random walk jumping algorithms do not perform well. It is not enough to simply guess at the next sample location; we need to make each iteration a viable draw from the posterior whenever we can, in order to have an efficient sampler for bigger models.\n",
    "\n",
    "Since Bayesian inference is all about calculating expectations over posteriors, what we seek is an algorithm that explores the area of the parameter space that contains most of the non-zero probability. This region is called the **typical set**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's a Typical Set?\n",
    "\n",
    "The typical set is where most of the **probability** lies in a particular volume associated with the distribution. As the dimension of a model increases, this set moves progressively further from the mode, and becomes more singular, as the result of concentration of measure.\n",
    "\n",
    "The typical set is a product of both the **density**, which is highest at the mode, and **volume** (that we integrate over), which increasingly becomes larger away from the mode as dimensionality increases. In fact, at high dimensions, the region around the mode contributes almost nothing to the expectation. Random walk methods have trouble finding and traversing this set efficiently. We need an algorithm that will find this narrow region and explore it efficiently."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![from Betancourt 2018](images/typicalset.png)\n",
    "\n",
    "In this context, and when sampling from continuous variables, **Hamiltonian Monte\n",
    "Carlo (HMC)** can prove to be a powerful tool. It avoids\n",
    "random walk behavior by **simulating a physical system** governed by\n",
    "Hamiltonian dynamics, potentially avoiding tricky conditional\n",
    "distributions in the process.\n",
    "\n",
    "HMC introduces two key concepts:\n",
    "\n",
    "1. **Momentum variables**: In addition to position variables (our parameters of interest), HMC introduces momentum variables, creating a phase space.\n",
    "2. **Hamiltonian dynamics**: It uses physical dynamics to guide proposals along trajectories that maintain constant energy.\n",
    "\n",
    "In HMC, model samples are obtained by simulating a physical system,\n",
    "where particles move about a high-dimensional landscape, subject to\n",
    "potential and kinetic energies. Adapting the notation from [Neal (1993)](http://www.cs.toronto.edu/~radford/review.abstract.html),\n",
    "particles are characterized by a position vector or state\n",
    "$s \\in \\mathcal{R}^D$ and velocity vector $\\phi \\in \\mathcal{R}^D$. The\n",
    "combined state of a particle is denoted as $\\chi=(s,\\phi)$. \n",
    "\n",
    "The joint **canonical distribution** of the position and velocity can be expressed as a product of the marginal position (which is of interest) and the conditional distribution of the velocity:\n",
    "\n",
    "$$\\pi(s, \\phi) = \\pi(\\phi | s) \\pi(s)$$\n",
    "\n",
    "This joint probability can also be written in terms of an invariant **Hamiltonian function**:\n",
    "\n",
    "$$\\pi(s, \\phi) \\propto \\exp(-H(s,\\phi))$$\n",
    "\n",
    "The Hamiltonian is then defined as the sum of potential energy $E(s)$ and kinetic energy\n",
    "$K(\\phi)$, as follows:\n",
    "\n",
    "$$\\mathcal{H}(s,\\phi) = E(s) + K(\\phi)\n",
    "= E(s) + \\frac{1}{2} \\sum_i \\phi_i^2$$\n",
    "\n",
    "Instead of sampling $p(s)$ directly, HMC operates by sampling from the canonical distribution.\n",
    "\n",
    "$$p(s,\\phi) = \\frac{1}{Z} \\exp(-\\mathcal{H}(s,\\phi))=p(s)p(\\phi)$$\n",
    "\n",
    "If we choose a momentum that is independent of position, marginalizing over $\\phi$ is\n",
    "trivial and recovers the original distribution of interest.\n",
    "\n",
    "Note that the Hamiltonian $\\mathcal{H}$ is independent of the parameterization of the model, and therefore, captures the geometry of the phase space distribution, including typical set. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hamiltonian Dynamics**\n",
    "\n",
    "State $s$ and velocity $\\phi$ are modified such that\n",
    "$\\mathcal{H}(s,\\phi)$ remains constant throughout the simulation. The\n",
    "differential equations are given by:\n",
    "\n",
    "$$\\begin{aligned}\\frac{ds_i}{dt} &= \\frac{\\partial \\mathcal{H}}{\\partial \\phi_i} = \\phi_i \\\\\n",
    "\\frac{d\\phi_i}{dt} &= - \\frac{\\partial \\mathcal{H}}{\\partial s_i}\n",
    "= - \\frac{\\partial E}{\\partial s_i}\n",
    "\\end{aligned}$$\n",
    "\n",
    "As shown in [Neal (1993)](http://www.cs.toronto.edu/~radford/review.abstract.html), \n",
    "the above transformation **preserves volume** and is\n",
    "**reversible** (*i.e.* satisfies detailed balance). The above dynamics can thus be used as transition operators\n",
    "of a Markov chain and will leave $p(s,\\phi)$ invariant. That chain by\n",
    "itself is not ergodic however, since simulating the dynamics maintains a\n",
    "fixed Hamiltonian $\\mathcal{H}(s,\\phi)$. HMC thus **alternates** Hamiltonian\n",
    "dynamic steps, with Gibbs sampling of the velocity. Because $p(s)$ and\n",
    "$p(\\phi)$ are independent, sampling $\\phi_{new} \\sim p(\\phi|s)$ is\n",
    "trivial since $p(\\phi|s)=p(\\phi)$, where $p(\\phi)$ is often taken to be\n",
    "the univariate Gaussian.\n",
    "\n",
    "![Skate park](images/skate_park.png?raw=true)\n",
    "\n",
    "**The Leap-Frog Algorithm**\n",
    "\n",
    "In practice, we cannot simulate Hamiltonian dynamics exactly because of\n",
    "the problem of time discretization. There are several ways one can do\n",
    "this. To maintain invariance of the Markov chain however, care must be\n",
    "taken to preserve the properties of *volume conservation* and *time\n",
    "reversibility*. The **leap-frog algorithm** maintains these properties\n",
    "and operates in 3 steps:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\phi_i(t + \\epsilon/2) &= \\phi_i(t) - \\frac{\\epsilon}{2} \\frac{\\partial{}}{\\partial s_i} E(s(t)) \\\\\n",
    "s_i(t + \\epsilon) &= s_i(t) + \\epsilon \\phi_i(t + \\epsilon/2) \\\\\n",
    "\\phi_i(t + \\epsilon) &= \\phi_i(t + \\epsilon/2) - \\frac{\\epsilon}{2} \\frac{\\partial{}}{\\partial s_i} E(s(t + \\epsilon)) \n",
    "\\end{aligned}$$\n",
    "\n",
    "We thus perform a half-step update of the velocity at time\n",
    "$t+\\epsilon/2$, which is then used to compute $s(t + \\epsilon)$ and\n",
    "$\\phi(t + \\epsilon)$.\n",
    "\n",
    "**Accept / Reject**\n",
    "\n",
    "In practice, using finite stepsizes $\\epsilon$ will not preserve\n",
    "$\\mathcal{H}(s,\\phi)$ exactly and will introduce bias in the simulation.\n",
    "Also, rounding errors due to the use of floating point numbers means\n",
    "that the above transformation will not be perfectly reversible.\n",
    "\n",
    "HMC cancels these effects **exactly** by adding a Metropolis\n",
    "accept/reject stage, after $n$ leapfrog steps. The new state\n",
    "$\\chi' = (s',\\phi')$ is accepted with probability $p_{acc}(\\chi,\\chi')$,\n",
    "defined as:\n",
    "\n",
    "$$p_{acc}(\\chi,\\chi') = min \\left( 1, \\frac{\\exp(-\\mathcal{H}(s',\\phi')}{\\exp(-\\mathcal{H}(s,\\phi)} \\right)$$\n",
    "\n",
    "**HMC Algorithm**\n",
    "\n",
    "We obtain a new HMC sample as follows:\n",
    "\n",
    "1.  sample a new velocity from a univariate Gaussian distribution\n",
    "2.  perform $n$ leapfrog steps to obtain the new state $\\chi'$\n",
    "3.  perform accept/reject move of $\\chi'$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No-U-Turn Sampler (NUTS)\n",
    "\n",
    "A key challenge with HMC is selecting appropriate values for the step size $\\epsilon$ and number of steps $L$. The No-U-Turn Sampler (NUTS) addresses this by:\n",
    "\n",
    "1. **Adaptively tuning the step size** during a warm-up phase to achieve a target acceptance rate\n",
    "2. **Dynamically determining the number of steps** by running the leapfrog integrator until a U-turn occurs (when the trajectory starts moving back toward its starting point)\n",
    "\n",
    "NUTS builds a binary tree of leapfrog steps and stops when the trajectory makes a U-turn. For each proposal, it starts with a single leapfrog step.\n",
    "It then doubles the length of the trajectory, simulating Hamiltonian dynamics both forwards and backwards in \"time\" from the current endpoints. This creates a balanced binary tree of states. It continues extending the trajectory by doubling the number of steps, subject to several conditions (related to detailed balance and ensuring good exploration). \n",
    "Once the doubling process stops (e.g., a U-turn is detected or a maximum tree depth is reached), a point is randomly sampled from all the states in the generated trajectory, with probabilities that ensure the overall sampler is valid.\n",
    "\n",
    "<img src=\"images/uturn.png\" alt=\"No-U-Turn Sampler illustration\" width=\"50%\">\n",
    "\n",
    "PyMC implements NUTS as its default sampler because of its efficiency for a wide range of problems. Let's see how to use it in practice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC in PyMC\n",
    "\n",
    "PyMC's core business is using Markov chain Monte Carlo to fit virtually any probability model. This involves the assignment and coordination of a suite of **step methods**, each of which is responsible for updating one or more variables. \n",
    "\n",
    "The user's interface to PyMC's sampling algorithms is the `sample` function, which coordinates the sampling process for a model.\n",
    "\n",
    "In the previous session, we specified a model for estimating basketball team strength based on game outcomes. Let's now try and fit this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data = pl.read_parquet('../data/ncaa_team_data.parquet')\n",
    "game_data = pl.read_parquet(\"../data/ncaa_game_data.parquet\")\n",
    "\n",
    "predictor_cols = ['FG%', '3P%', 'FT%', 'ORB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF']\n",
    "\n",
    "# Standardize the predictor columns in polars\n",
    "X = team_data.select(\n",
    "    [(pl.col(c) - pl.col(c).mean()) / pl.col(c).std() for c in predictor_cols]\n",
    ")\n",
    "\n",
    "y = game_data['home_margin'].to_numpy()\n",
    "\n",
    "coords = dict(\n",
    "    predictor=predictor_cols,\n",
    "    team=team_data[\"School\"].to_list()\n",
    ")\n",
    "\n",
    "with pm.Model(coords=coords) as ncaa_model:\n",
    "    \n",
    "    # Predictor coefficients\n",
    "    beta = pm.Normal('beta', 0, sigma=10, dims=\"predictor\")\n",
    "\n",
    "    # Home advantage\n",
    "    home_advantage = pm.HalfNormal('home_advantage', sigma=10)\n",
    "\n",
    "    # Observation error\n",
    "    sigma = pm.HalfCauchy('sigma', 1)\n",
    "\n",
    "    team_strength = pm.Deterministic('team_strength', beta.dot(X.to_numpy().T), dims=\"team\")\n",
    "\n",
    "    expected_margin = home_advantage + team_strength[game_data['home_team_id'].to_numpy()] - team_strength[game_data['away_team_id'].to_numpy()]\n",
    "\n",
    "    pm.Normal('outcome', expected_margin, sigma=sigma, observed=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see what happens when you run `pm.sample` with no arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ncaa_model:\n",
    "    idata = pm.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supported sampling methods\n",
    "\n",
    "PyMC offers a range of sampling methods to accommodate different model requirements:\n",
    "\n",
    "1. **NUTS (No U-Turn Sampler)** - The default for continuous variables, an advanced HMC variant that automatically tunes parameters\n",
    "\n",
    "2. **HamiltonianMC** - Basic Hamiltonian Monte Carlo implementation for continuous variables\n",
    "\n",
    "3. **Metropolis** - Classic Metropolis-Hastings algorithm that can handle continuous and discrete variables\n",
    "\n",
    "4. **BinaryMetropolis** - Specialized algorithm for binary (boolean) variables\n",
    "\n",
    "5. **Slice** - Slice sampling algorithm\n",
    "\n",
    "6. **SGMC (Stochastic Gradient MCMC)** - Methods that use gradient information for large datasets\n",
    "\n",
    "The `sample` function generally selects the appropriate method automatically based on the variable types in your model, though you can manually specify methods if needed.There is rarely a reason to use `HamiltonianMC` rather than `NUTS`. It is the default sampler for continuous variables in PyMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic assignment of step methods\n",
    "\n",
    "When `step` is not specified by the user, PyMC will assign step methods to variables automatically. To do so, each step method implements a class method called `Competence`. This method returns a value from 0 (incompatible) to 3 (ideal), based on the attributes of the random variable in question. `sample()` assigns the step method that returns the highest competence value to each of its unallocated stochastic random variables. In general:\n",
    "\n",
    "* Binary variables will be assigned to `BinaryMetropolis` (Metropolis-Hastings for binary values)\n",
    "* Discrete variables will be assigned to `Metropolis`\n",
    "* Continuous variables will be assigned to `NUTS` (No U-turn Sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel sampling\n",
    "\n",
    "Nearly all modern desktop computers have multiple CPU cores, and running multiple MCMC chains is an **embarrasingly parallel** computing task. It is therefore relatively simple to run chains in parallel in PyMC. This is done by setting the `cores` argument in `sample` to some value between 2 and the number of cores on your machine (you can specify more chains than cores, but you will not gain efficiency by doing so). The default value of `cores` is `None`, which will select the number of CPUs on your machine, to a maximum of 4. \n",
    "\n",
    "> Keep in mind that some chains might themselves be multithreaded via openmp or BLAS. In those cases it might be faster to set this to 1.\n",
    "\n",
    "However, note that the number of chains sampled can be set independently of the number of cores by specifying the `chains` argument.\n",
    "\n",
    "```python\n",
    "with my_model:\n",
    "    trace = pm.sample(chains=4, cores=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running $n$ iterations with $c$ chains will result in $c \\times n$ samples.\n",
    "\n",
    "Generating several chains is generally recommended because it aids in model checking, allowing statistics such as the potential scale reduction factor ($\\hat{R}$) and effective sample size to be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ncaa_model:\n",
    "    # Sample 2 chains in parallel using 2 cores\n",
    "    trace = pm.sample(1000, tune=1000, chains=2, cores=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JAX-based Samplers\n",
    "\n",
    "An alternative to PyMC's PyTensor-based samplers are samplers written in JAX. Using these samplers, all the operations needed to compute a posterior can be performed under JAX, reducing the Python overhead during sampling and leveraging all JAX performance improvements and features like the ability to sample on GPUs or TPUs.\n",
    "\n",
    "PyMC offers NUTS JAX samplers via [NumPyro](https://num.pyro.ai/en/latest/index.html) or [Nutpie](https://github.com/pymc-devs/nutpie). Significantly, NumPyro and Nutpie can both be used because in PyMC the modeling language is decoupled from the inference methods; NumPyro and Nutpie only require a log-probability density function written in JAX. This demonstrates that samplers can be developed independently of PyMC and then be made available to users of the library.\n",
    "\n",
    "The JAX samplers can be invoked using the `nuts_sampler` argument for `pm.sample`, either using the Numpyro backend or the Nutpie backend:\n",
    "\n",
    "```python\n",
    "pm.sample(nuts_sampler=\"numpyro\")\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```python\n",
    "pm.sample(nuts_sampler=\"nutpie\", nuts_sampler_kwargs={\"backend\": \"jax\"})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ncaa_model:\n",
    "    # Use the Nutpie JAX sampler\n",
    "    trace = pm.sample(nuts_sampler=\"numpyro\", nuts_sampler_kwargs={\"chain_method\": \"parallel\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## References\n",
    "\n",
    "Betancourt, M. (2018). A Conceptual Introduction to Hamiltonian Monte Carlo. arXiv:1209.3572v1 [stat.CO].\n",
    "\n",
    "Doucet, A., De Freitas, N., and Gordon, N. (2001), Sequential Monte Carlo Methods in Practice, Statistics for Engineering and Information Science, New York: Springer-Verlag.\n",
    "\n",
    "Chapter 6 of [Givens, Geof H.; Hoeting, Jennifer A. (2012-10-09). Computational Statistics (Wiley Series in Computational Statistics)](http://www.stat.colostate.edu/computationalstatistics/)\n",
    "\n",
    "Chapter 5 of [Albert, J. (2009). Bayesian computation with R.](http://www.amazon.com/Bayesian-Computation-R-Use/dp/0387922970)\n",
    "\n",
    "Gelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (2003). Bayesian Data Analysis, Second Edition (Chapman & Hall/CRC Texts in Statistical Science) (2nd ed.). Chapman and Hall/CRC.\n",
    "\n",
    "Neal, R. M. (2003). Slice sampling. The Annals of Statistics, 31(3), 705–767. doi:10.1111/1467-9868.00198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
